import streamlit as st
import gdown
import os
# –ù–µ–æ–±—Ö—ñ–¥–Ω–∏–π —ñ–º–ø–æ—Ä—Ç –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –∞—Ä—Ö—ñ–≤–∞–º–∏
import zipfile 

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏ ---
st.set_page_config(
    page_title="AI Text Detector (BERT, CNN, SVM)",
    page_icon="üîé",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —à–ª—è—Ö—ñ–≤ —Ç–∞ ID ---
# –®–ª—è—Ö–∏ –¥–æ –º–æ–¥–µ–ª–µ–π (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ–¥–∏–Ω —ñ —Ç–æ–π —Å–∞–º–∏–π –∫–∞—Ç–∞–ª–æ–≥)
MODELS_DIR = './models'
os.makedirs(MODELS_DIR, exist_ok=True)

# !!! –£–í–ê–ì–ê: –ó–ê–ú–Ü–ù–Ü–¢–¨ –¶–ï–ô PLACEHOLDER –ù–ê –†–ï–ê–õ–¨–ù–ò–ô ID –í–ê–®–û–ì–û ZIP-–ê–†–•–Ü–í–£ CNN !!!
CNN_MODEL_ZIP_ID = '1lLGHDE0o_aJyUOVbJ37fspImQRKKTrjA'
CNN_MODEL_ZIP_FILENAME = "cnn_model.zip"

# ID —Ñ–∞–π–ª—ñ–≤ –º–æ–¥–µ–ª–µ–π –∑ Google Drive
MODEL_IDS = {
    "svm_model": "1_O8mtsgJipuCgqrW1yBoJBUUEYCiUXsx", # svm_linear_model_90000_features_probability.pkl
    "tfidf_vectorizer": "1HBpIvydoh6slZKwrX4o9hsinGPydwkIi", # tfidf_vectorizer_90000_features.pkl
    "bert_binary": "1D8wp3sOVV9Ri5BUG26IGVSZoSZlvjobD", # model_bertbase_updated.pt
    "bert_multiclass": "1GhTr-2ghquSTWdha96s7JJWegx2yoo2t", # model_multiclass.pt
    "cnn_zip": CNN_MODEL_ZIP_ID, # ID –¥–ª—è ZIP-—Ñ–∞–π–ª—É –º–æ–¥–µ–ª—ñ CNN
}

# –®–ª—è—Ö–∏ –¥–æ —Ñ–∞–π–ª—ñ–≤
PATHS = {
    "svm_model": os.path.join(MODELS_DIR, "svm_linear_model_90000_features_probability.pkl"),
    "tfidf_vectorizer": os.path.join(MODELS_DIR, "tfidf_vectorizer_90000_features.pkl"),
    "bert_binary": os.path.join(MODELS_DIR, "model_bertbase_updated.pt"),
    "bert_multiclass": os.path.join(MODELS_DIR, "model_multiclass.pt"),
    "cnn_zip": os.path.join(MODELS_DIR, CNN_MODEL_ZIP_FILENAME),
    "cnn_model_dir": os.path.join(MODELS_DIR, "model_autokeras_gltr_trials_8"), # –ö—ñ–Ω—Ü–µ–≤–∏–π —à–ª—è—Ö –¥–ª—è CNN
}

# --- –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤ –º–æ–¥–µ–ª–µ–π ---
def download_models(model_paths):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Ñ–∞–π–ª–∏ –º–æ–¥–µ–ª–µ–π –∑ Google Drive, —è–∫—â–æ –≤–æ–Ω–∏ –≤—ñ–¥—Å—É—Ç–Ω—ñ."""
    
    # –°–ø–æ—á–∞—Ç–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ç–∞ –æ–±—Ä–æ–±–ª—è—î–º–æ CNN SavedModel (ZIP)
    cnn_target_dir = PATHS["cnn_model_dir"]
    cnn_zip_path = PATHS["cnn_zip"]
    cnn_zip_id = MODEL_IDS["cnn_zip"]
    
    if not os.path.exists(cnn_target_dir) and cnn_zip_id != '1lLGHDE0o_aJyUOVbJ37fspImQRKKTrjA':
        with st.empty():
            st.info("Downloading CNN/GLTR model (SavedModel ZIP)...")
            try:
                # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è ZIP
                gdown.download(f'https://drive.google.com/uc?id={cnn_zip_id}', cnn_zip_path, quiet=False)
                st.success("CNN ZIP downloaded successfully. Starting extraction...")
                
                # 2. –†–æ–∑–ø–∞–∫—É–≤–∞–Ω–Ω—è
                with zipfile.ZipFile(cnn_zip_path, 'r') as zip_ref:
                    # –†–æ–∑–ø–∞–∫–æ–≤—É—î–º–æ –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –≤ –∫–∞—Ç–∞–ª–æ–≥ models, 
                    # –ø—Ä–∏–ø—É—Å–∫–∞—é—á–∏, —â–æ cnn_model.zip –º—ñ—Å—Ç–∏—Ç—å –ø–∞–ø–∫—É model_autokeras_gltr_trials_8
                    zip_ref.extractall(MODELS_DIR) 
                
                # 3. –í–∏–¥–∞–ª–µ–Ω–Ω—è ZIP-—Ñ–∞–π–ª—É
                os.remove(cnn_zip_path)
                st.success(f"CNN/GLTR model extracted and ready at {cnn_target_dir}!")
                
            except Exception as e:
                st.error(f"Error processing CNN model (ZIP/Extraction): {e}. Check if the ZIP file contains the directory 'model_autokeras_gltr_trials_8'.")
                st.session_state['cnn_error_setup'] = str(e)
                # –ú–∏ –Ω–µ –∑—É–ø–∏–Ω—è—î–º–æ, —â–æ–± –º–æ–∂–Ω–∞ –±—É–ª–æ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —ñ–Ω—à—ñ –º–æ–¥–µ–ª—ñ
    elif cnn_zip_id == '1lLGHDE0o_aJyUOVbJ37fspImQRKKTrjA':
        st.warning("–ë—É–¥—å –ª–∞—Å–∫–∞, –æ–Ω–æ–≤—ñ—Ç—å App.py –∑ —Ä–µ–∞–ª—å–Ω–∏–º Google Drive ID –¥–ª—è –º–æ–¥–µ–ª—ñ CNN.")

    
    # –¢–µ–ø–µ—Ä –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —ñ–Ω—à—ñ, –ø–æ–æ–¥–∏–Ω–æ–∫—ñ —Ñ–∞–π–ª–∏
    for key in ["svm_model", "tfidf_vectorizer", "bert_binary", "bert_multiclass"]:
        path = model_paths[key]
        if key in MODEL_IDS and not os.path.exists(path):
            with st.empty():
                try:
                    st.info(f"Downloading {key}...")
                    gdown.download(f'https://drive.google.com/uc?id={MODEL_IDS[key]}', path, quiet=False)
                    st.success(f"{key} downloaded successfully!")
                except Exception as e:
                    st.error(f"Error downloading {key}: {e}")
                    st.session_state[f'{key}_error_setup'] = str(e)

# --- UI ---
st.title("üîé –ú—É–ª—å—Ç–∏–º–æ–¥–µ–ª—å–Ω–∏–π –î–µ—Ç–µ–∫—Ç–æ—Ä –¢–µ–∫—Å—Ç—É, –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ–≥–æ –®—Ç—É—á–Ω–∏–º –Ü–Ω—Ç–µ–ª–µ–∫—Ç–æ–º (AI)")

text_to_check = st.text_area(
    "–í—Å—Ç–∞–≤—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É:",
    height=300,
    value="–¶–µ –ø—Ä–æ—Å—Ç–æ –∑–≤–∏—á–∞–π–Ω–∏–π —Ç–µ—Å—Ç–æ–≤–∏–π —Ç–µ–∫—Å—Ç, –Ω–∞–ø–∏—Å–∞–Ω–∏–π –ª—é–¥–∏–Ω–æ—é, —â–æ–± –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏, —è–∫ –ø—Ä–∞—Ü—é—î –≤–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞ –≤–∏—è–≤–ª–µ–Ω–Ω—è –®–Ü. –ß–∏ –∑–º–æ–∂–µ –≤–æ–Ω–∞ –º–µ–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏?",
    key="text_input"
)

st.caption("–°–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ–≤—ñ—Ä—è—î —Ç–µ–∫—Å—Ç –Ω–∞ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é —á–æ—Ç–∏—Ä—å–æ—Ö —Ä—ñ–∑–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π: SVM/TF-IDF, –±—ñ–Ω–∞—Ä–Ω–∏–π BERT, –±–∞–≥–∞—Ç–æ–∫–ª–∞—Å–æ–≤–∏–π BERT —Ç–∞ CNN/GLTR.")

# –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫—É –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
button_pressed = st.button("–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –Ω–∞ AI", type="primary")

# --- –û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞: –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π —Ç–∞ –∑–∞–ø—É—Å–∫ –∞–Ω–∞–ª—ñ–∑—É ---

# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤—Å—ñ —Ñ–∞–π–ª–∏. –§—É–Ω–∫—Ü—ñ—è —Ç–µ–ø–µ—Ä –æ–±—Ä–æ–±–ª—è—î ZIP –¥–ª—è CNN.
download_models(PATHS)

if button_pressed:
    if not text_to_check.strip():
        st.warning("–ë—É–¥—å –ª–∞—Å–∫–∞, –≤—Å—Ç–∞–≤—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.")
    else:
        # –Ü–º–ø–æ—Ä—Ç utils –≤—ñ–¥–±—É–≤–∞—î—Ç—å—Å—è —Ç—É—Ç, —â–æ–± —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª–µ–π –±—É–ª–∞ –ª—ñ–Ω–∏–≤–æ—é
        with st.spinner("–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª–µ–π —Ç–∞ –±—ñ–±–ª—ñ–æ—Ç–µ–∫... (–ü–µ—Ä—à–∏–π –∑–∞–ø—É—Å–∫ –º–æ–∂–µ –∑–∞–π–Ω—è—Ç–∏ –¥–æ —Ö–≤–∏–ª–∏–Ω–∏)"):
            try:
                # –í–°–¢–ê–ù–û–í–õ–ï–ù–ù–Ø –®–õ–Ø–•–Ü–í –£ –°–ï–°–Ü–Æ –î–õ–Ø UTILS
                st.session_state['SVM_MODEL_PATH'] = PATHS["svm_model"]
                st.session_state['SVM_VECTORIZER_PATH'] = PATHS["tfidf_vectorizer"]
                st.session_state['BERT_MODEL_PATH'] = PATHS["bert_binary"]
                st.session_state['BERT_MULTICLASS_PATH'] = PATHS["bert_multiclass"]
                # –®–ª—è—Ö –¥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó SavedModel
                st.session_state['CNN_MODEL_PATH'] = PATHS["cnn_model_dir"] 
                
                import utils
                
                # –¢–µ–ø–µ—Ä utils –¥–æ—Å—Ç—É–ø–Ω–∏–π, —ñ –º–∏ –º–æ–∂–µ–º–æ –π–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏
                no_cyrillic = not utils.has_cyrillic(text_to_check)
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –∫–∏—Ä–∏–ª–∏—Ü—ñ
                if no_cyrillic:
                    st.error("‚ö†Ô∏è –£–≤–∞–≥–∞: –í–≤–µ–¥–µ–Ω–∏–π —Ç–µ–∫—Å—Ç –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –∫–∏—Ä–∏–ª–∏—Ü—ñ. –°–∏—Å—Ç–µ–º–∞ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó —Ç–∞ —Ä–æ—Å—ñ–π—Å—å–∫–æ—ó –º–æ–≤. –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è —Ç–µ–∫—Å—Ç—É –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—é –∞–±–æ —ñ–Ω—à–æ—é –º–æ–≤–æ—é –º–æ–∂—É—Ç—å –±—É—Ç–∏ –Ω–µ—Ç–æ—á–Ω–∏–º–∏.")
                
                # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª—ñ–∑—É
                results, multiclass_results = utils.run_analysis(text_to_check)
                
                # --- –í–∏–≤–µ–¥–µ–Ω–Ω—è –†–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ ---
                st.header("üìä –ó–≤–µ–¥–µ–Ω–∏–π –†–µ–∑—É–ª—å—Ç–∞—Ç –ê–Ω–∞–ª—ñ–∑—É")
                
                # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∑–≤–µ–¥–µ–Ω–Ω—è
                col1, col2 = st.columns(2)

                with col1:
                    st.subheader("–ë—ñ–Ω–∞—Ä–Ω–∞ –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è (AI / Human)")
                    for model_name, (is_ai, prob) in results.items():
                        # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ CNN, —è–∫—â–æ –≤–æ–Ω–∞ –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏–ª–∞—Å—è
                        if prob is None:
                            continue
                        
                        st.metric(
                            label=model_name,
                            value="AI ü§ñ" if is_ai else "–õ—é–¥–∏–Ω–∞ ‚úçÔ∏è",
                            delta=f"–í–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å: {prob:.2f}%",
                            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ–Ω–≤–µ—Ä—Å–Ω–∏–π –∫–æ–ª—ñ—Ä –¥–ª—è AI
                            delta_color="inverse" if is_ai else "normal"
                        )

                with col2:
                    st.subheader("–ë–∞–≥–∞—Ç–æ–∫–ª–∞—Å–æ–≤–∞ –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è (Multiclass BERT)")
                    if multiclass_results:
                        for label, prob in multiclass_results.items():
                            st.metric(
                                label=label,
                                value=f"{prob:.2f}%",
                                delta_color="off"
                            )
                    else:
                        st.info("–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –±–∞–≥–∞—Ç–æ–∫–ª–∞—Å–æ–≤–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ.")


                st.header("üî¨ –î–µ—Ç–∞–ª—å–Ω–∏–π –ê–Ω–∞–ª—ñ–∑")

                with st.expander("–ü–æ—è—Å–Ω–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π"):
                    st.markdown("""
                    **SVM/TF-IDF:** –ö–ª–∞—Å–∏—á–Ω–∞ –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è, —è–∫–∞ –±–∞–∑—É—î—Ç—å—Å—è –Ω–∞ —á–∞—Å—Ç–æ—Ç—ñ —Å–ª—ñ–≤ —Ç–∞ —ó—Ö–Ω—ñ—Ö –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π. –®–≤–∏–¥–∫–∞, –∞–ª–µ –º–µ–Ω—à —Ç–æ—á–Ω–∞.  
                    **BERT (–ë—ñ–Ω–∞—Ä–Ω–∏–π):** –ú–æ–¥–µ–ª—å –≥–ª–∏–±–æ–∫–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è, –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–∞ –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è, —á–∏ —î —Ç–µ–∫—Å—Ç AI-–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏–º (ChatGPT/GPT-3).  
                    **BERT (–ë–∞–≥–∞—Ç–æ–∫–ª–∞—Å–æ–≤–∏–π):** –ù–∞–º–∞–≥–∞—î—Ç—å—Å—è –≤–∏–∑–Ω–∞—á–∏—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (ChatGPT, GPT-3, T5, LLaMA).  
                    **CNN/GLTR:** –ù–∞–≤—á–∞–ª–∞—Å—è –Ω–∞ –æ–∑–Ω–∞–∫–∞—Ö, –ø–æ–≤'—è–∑–∞–Ω–∏—Ö –∑ —Ç–∏–º, —è–∫ –®–Ü –æ–±–∏—Ä–∞—î –Ω–∞—Å—Ç—É–ø–Ω–µ —Å–ª–æ–≤–æ (GLTR). 
                    """)
                    
                # –î–æ–¥–∞–º–æ –µ–ª–µ–º–µ–Ω—Ç, —â–æ–± –ø–æ–∫–∞–∑–∞—Ç–∏, —â–æ CNN –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏–ª–∞—Å—å
                if 'cnn_error' in st.session_state:
                    st.warning(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó CNN/GLTR: {st.session_state['cnn_error']}")


            except Exception as e:
                st.error(f"‚ùå –°—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∞–Ω–∞–ª—ñ–∑—É. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑ –∞–±–æ –ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ –≤–≤–µ–¥–µ–Ω–∏–π —Ç–µ–∫—Å—Ç.")
                st.exception(e)